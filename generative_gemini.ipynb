{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pydantic 2.9.2\n",
      "Uninstalling pydantic-2.9.2:\n",
      "  Successfully uninstalled pydantic-2.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall pydantic -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pydantic in /Users/stephenvu9686/Library/Python/3.9/lib/python/site-packages (2.10.6)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/stephenvu9686/Library/Python/3.9/lib/python/site-packages (from pydantic) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/stephenvu9686/Library/Python/3.9/lib/python/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/stephenvu9686/Library/Python/3.9/lib/python/site-packages (from pydantic) (4.12.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pydantic\n",
    "# %pip install pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "#AIzaSyAgppWUfweq78A40VUyG3NhYf0zlDysTr8\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAgppWUfweq78A40VUyG3NhYf0zlDysTr8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, the user just asked me, \"Hello, how are you?\" That's a friendly greeting. I should respond in a warm and welcoming way.\n",
      "\n",
      "I want to make sure they feel comfortable asking for help or share something new. Maybe add a smiley emoji to keep it warm and approachable.\n",
      "</think>\n",
      "\n",
      "Hello! How are you doing? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "USER_NAME = \"Person A\"  # The name for interacting with the agent\n",
    "LLM = ChatOllama(model=\"deepseek-r1:1.5b\", max_tokens=1500)  # Use your local model\n",
    "response = LLM.invoke(\"Hello, how are you?\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime, timedelta\n",
    "# from pydantic import BaseModel, Field\n",
    "# # import openai\n",
    "# from langchain.docstore import InMemoryDocstore\n",
    "# from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "# from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI,GoogleGenerativeAIEmbeddings\n",
    "# from termcolor import colored\n",
    "# from langchain_experimental.generative_agents import (\n",
    "#     GenerativeAgent,\n",
    "#     GenerativeAgentMemory,\n",
    "# )\n",
    "# import math\n",
    "# import numpy as np\n",
    "# from sklearn.decomposition import NMF\n",
    "# from typing import Dict, List, Optional\n",
    "# import faiss\n",
    "# from langchain_community.llms import GPT4All\n",
    "# from typing import List, Optional\n",
    "# from langchain.callbacks.base import Callbacks\n",
    "# import pandas as pd \n",
    "# import matplotlib.pyplot as plt  # Ensure this is imported\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from typing import Dict, List, Optional, Tuple, Set\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_experimental.generative_agents import (\n",
    "    GenerativeAgent,\n",
    "    GenerativeAgentMemory,\n",
    ")\n",
    "from langchain.callbacks.base import Callbacks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Override Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Base memory structure (as provided in the notebook)\n",
    "class MemoryItem(BaseModel):\n",
    "    content: str\n",
    "    created_at: datetime\n",
    "    importance: Optional[float] = 0.0\n",
    "\n",
    "\n",
    "class BaseCache(BaseModel):\n",
    "    memories: Dict[str, MemoryItem] = Field(default_factory=dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LLM Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM with Google Generative AI\n",
    "LLM = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_new_memory_retriever():\n",
    "    \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n",
    "    # Initialize the vectorstore as empty\n",
    "    embedding_size = 768  # fixed to match with GoogleEmbedding\n",
    "    index = faiss.IndexFlatL2(embedding_size)\n",
    "    vectorstore = FAISS(\n",
    "        embeddings_model.embed_query,\n",
    "        index,\n",
    "        InMemoryDocstore({}),\n",
    "        {},\n",
    "        relevance_score_fn=relevance_score_fn,\n",
    "    )\n",
    "    return TimeWeightedVectorStoreRetriever(\n",
    "        vectorstore=vectorstore, other_score_keys=[\"importance\"], k=15\n",
    "    )\n",
    "\n",
    "# Helper functions for agent creation (from the notebook)\n",
    "def relevance_score_fn(score: float) -> float:\n",
    "    \"\"\"Return a similarity score on a scale [0, 1].\"\"\"\n",
    "    # Convert euclidean norm of normalized embeddings to similarity function\n",
    "    return 1.0 - score / math.sqrt(2)\n",
    "\n",
    "\n",
    "\n",
    "def interview_agent(agent: GenerativeAgent, message: str) -> str:\n",
    "    \"\"\"Help interact with the agent.\"\"\"\n",
    "    new_message = f\"{agent.name} says {message}\"\n",
    "    return agent.generate_dialogue_response(new_message)[1]\n",
    "GenerativeAgentMemory.model_rebuild()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. HallAgent4Rec class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   item_id  name  category  price  popularity\n",
      "0      101     0         0     10         0.8\n",
      "1      102     1         2     50         0.6\n",
      "Created interaction matrix of shape (5, 10)\n",
      "Loaded data: 5 users, 10 items, 13 interactions\n",
      "Clustering 10 items into 3 clusters...\n",
      "Created user-cluster matrix of shape (5, 3)\n",
      "Item clustering complete. Cluster distribution:\n",
      "Cluster 2: 4 items\n",
      "Cluster 0: 4 items\n",
      "Cluster 1: 2 items\n",
      "Starting hallucination-aware matrix factorization...\n",
      "Iteration 10/100, Error: 0.9461, Learning Rate: 0.009991\n",
      "Iteration 20/100, Error: 0.9028, Learning Rate: 0.009981\n",
      "Iteration 30/100, Error: 0.8551, Learning Rate: 0.009971\n",
      "Iteration 40/100, Error: 0.8011, Learning Rate: 0.009961\n",
      "Iteration 50/100, Error: 0.7403, Learning Rate: 0.009951\n",
      "Iteration 60/100, Error: 0.6738, Learning Rate: 0.009941\n",
      "Iteration 70/100, Error: 0.6043, Learning Rate: 0.009931\n",
      "Iteration 80/100, Error: 0.5351, Learning Rate: 0.009922\n",
      "Iteration 90/100, Error: 0.4698, Learning Rate: 0.009912\n",
      "Iteration 100/100, Error: 0.4112, Learning Rate: 0.009902\n",
      "Matrix factorization complete\n",
      "Initializing generative agents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized 5 generative agents\n",
      "HallAgent4Rec training complete!\n",
      "Generating recommendations for user 1...\n",
      "item_name:  9.0\n",
      "retrieved_name:  6.0\n",
      "item_name:  9.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  9.0\n",
      "retrieved_name:  9.0\n",
      "item_name:  6.0\n",
      "retrieved_name:  6.0\n",
      "item_name:  6.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  6.0\n",
      "retrieved_name:  9.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  6.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  9.0\n",
      "Detected 3 hallucinations: ['9.0', '6.0', '3.0']\n",
      "Generated 3 valid recommendations\n",
      "Recommendations for User 1:\n",
      "1. 9.0 - 1.0 ($35.0)\n",
      "2. 6.0 - 1.0 ($25.0)\n",
      "3. 3.0 - 1.0 ($30.0)\n",
      "Generating recommendations for user 1...\n",
      "item_name:  6.0\n",
      "retrieved_name:  6.0\n",
      "item_name:  6.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  6.0\n",
      "retrieved_name:  9.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  6.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  9.0\n",
      "item_name:  9.0\n",
      "retrieved_name:  6.0\n",
      "item_name:  9.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  9.0\n",
      "retrieved_name:  9.0\n",
      "item_name:  6.0\n",
      "retrieved_name:  6.0\n",
      "item_name:  6.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  6.0\n",
      "retrieved_name:  9.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  6.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  9.0\n",
      "item_name:  9.0\n",
      "retrieved_name:  6.0\n",
      "item_name:  9.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  9.0\n",
      "retrieved_name:  9.0\n",
      "item_name:  6.0\n",
      "retrieved_name:  6.0\n",
      "item_name:  6.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  6.0\n",
      "retrieved_name:  9.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  6.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  9.0\n",
      "item_name:  9.0\n",
      "retrieved_name:  6.0\n",
      "item_name:  9.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  9.0\n",
      "retrieved_name:  9.0\n",
      "item_name:  6.0\n",
      "retrieved_name:  6.0\n",
      "item_name:  6.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  6.0\n",
      "retrieved_name:  9.0\n",
      "Detected 10 hallucinations: ['6.0', '3.0', '9.0', '6.0', '3.0', '9.0', '6.0', '3.0', '9.0', '6.0']\n",
      "Generated 4 valid recommendations\n",
      "Generating recommendations for user 2...\n",
      "item_name:  3.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  1.0\n",
      "item_name:  1.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  1.0\n",
      "retrieved_name:  1.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  1.0\n",
      "item_name:  1.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  1.0\n",
      "retrieved_name:  1.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  1.0\n",
      "item_name:  1.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  1.0\n",
      "retrieved_name:  1.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  1.0\n",
      "item_name:  1.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  1.0\n",
      "retrieved_name:  1.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  3.0\n",
      "retrieved_name:  1.0\n",
      "item_name:  1.0\n",
      "retrieved_name:  3.0\n",
      "item_name:  1.0\n",
      "retrieved_name:  1.0\n",
      "Detected 10 hallucinations: ['3.0', '1.0', '3.0', '1.0', '3.0', '1.0', '3.0', '1.0', '3.0', '1.0']\n",
      "Generated 4 valid recommendations\n",
      "Generating recommendations for user 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Resource has been exhausted (e.g. check quota).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 728\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 728\u001b[0m     \u001b[43mexample_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 721\u001b[0m, in \u001b[0;36mexample_usage\u001b[0;34m()\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ($\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    720\u001b[0m \u001b[38;5;66;03m# Evaluate the system\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m \u001b[43mhall_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_interactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluation Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric, value \u001b[38;5;129;01min\u001b[39;00m eval_results\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[20], line 563\u001b[0m, in \u001b[0;36mHallAgent4Rec.evaluate\u001b[0;34m(self, test_interactions, metrics)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user_id, test_items \u001b[38;5;129;01min\u001b[39;00m user_test_items\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_id_map:\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;66;03m# Generate recommendations\u001b[39;00m\n\u001b[0;32m--> 563\u001b[0m         recommendations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_recommendations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m recommendations:\n\u001b[1;32m    565\u001b[0m             recommended_items \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m recommendations]\n",
      "Cell \u001b[0;32mIn[20], line 429\u001b[0m, in \u001b[0;36mHallAgent4Rec.generate_recommendations\u001b[0;34m(self, user_id, num_recommendations)\u001b[0m\n\u001b[1;32m    410\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;124mYou are a recommendation system for a user with the following traits:\u001b[39m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent\u001b[38;5;241m.\u001b[39mtraits\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;124m...\u001b[39m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# Generate recommendations\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mLLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m recommendations_text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# Step 5: Detect hallucinations\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# Extract recommended items from response\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py:284\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    283\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 284\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py:860\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    854\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    859\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py:690\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 690\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m         )\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py:925\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 925\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    929\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_google_genai/chat_models.py:951\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    927\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    939\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m    940\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    941\u001b[0m         messages,\n\u001b[1;32m    942\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    949\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[1;32m    950\u001b[0m     )\n\u001b[0;32m--> 951\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_google_genai/chat_models.py:196\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m--> 196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tenacity/__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tenacity/__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tenacity/__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tenacity/__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:438\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:390\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tenacity/__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_google_genai/chat_models.py:194\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_google_genai/chat_models.py:178\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mFailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/google/api_core/timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[1;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 Resource has been exhausted (e.g. check quota)."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========== HallAgent4Rec Implementation Based on the Paper ===========\n",
    "\n",
    "class HallAgent4Rec:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_clusters: int = 10,\n",
    "        latent_dim: int = 20,\n",
    "        lambda_u: float = 0.1,\n",
    "        lambda_v: float = 0.1,\n",
    "        lambda_h: float = 1.0,\n",
    "        learning_rate: float = 0.01,\n",
    "        decay_rate: float = 0.0001,\n",
    "        max_iterations: int = 100,\n",
    "        similarity_threshold: float = 0.5,\n",
    "        relevance_threshold: float = 0.1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the HallAgent4Rec system.\n",
    "        \n",
    "        Args:\n",
    "            num_clusters: Number of clusters for item grouping\n",
    "            latent_dim: Dimensionality of user and item embeddings\n",
    "            lambda_u: User regularization coefficient\n",
    "            lambda_v: Item regularization coefficient\n",
    "            lambda_h: Hallucination penalty coefficient\n",
    "            learning_rate: Initial learning rate for optimization\n",
    "            decay_rate: Learning rate decay parameter\n",
    "            max_iterations: Maximum number of iterations for matrix factorization\n",
    "            similarity_threshold: Threshold for item similarity in retrieval\n",
    "            relevance_threshold: Threshold for item relevance in knowledge base\n",
    "        \"\"\"\n",
    "        self.num_clusters = num_clusters\n",
    "        self.latent_dim = latent_dim\n",
    "        self.lambda_u = lambda_u\n",
    "        self.lambda_v = lambda_v\n",
    "        self.lambda_h = lambda_h\n",
    "        self.learning_rate = learning_rate\n",
    "        self.decay_rate = decay_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.relevance_threshold = relevance_threshold\n",
    "        \n",
    "        # Initialize components\n",
    "        self.agents = {}  # Dictionary to store generative agents\n",
    "        self.clusters = None  # Will store the cluster model\n",
    "        self.cluster_assignments = None  # Will store item cluster assignments\n",
    "        self.user_embeddings = None  # Will store user embeddings from PMF\n",
    "        self.item_embeddings = None  # Will store item embeddings from PMF\n",
    "        self.user_cluster_matrix = None  # Will store user-cluster interaction matrix\n",
    "        self.item_features = None  # Will store item features for clustering\n",
    "        self.item_database = None  # Will store the item database\n",
    "        self.hallucination_scores = None  # Will store hallucination likelihood scores\n",
    "        self.items_by_cluster = {}  # Will store items grouped by cluster\n",
    "\n",
    "    def load_data(self, user_data: pd.DataFrame, item_data: pd.DataFrame, interactions: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Load user, item, and interaction data.\n",
    "        \n",
    "        Args:\n",
    "            user_data: DataFrame with user information (id, features, etc.)\n",
    "            item_data: DataFrame with item information (id, features, etc.)\n",
    "            interactions: DataFrame with user-item interactions\n",
    "        \"\"\"\n",
    "        self.user_data = user_data\n",
    "        self.item_data = item_data\n",
    "        self.interactions = interactions\n",
    "        \n",
    "        # Create a set of all users and items\n",
    "        self.all_users = set(user_data['user_id'].unique())\n",
    "        self.all_items = set(item_data['item_id'].unique())\n",
    "        \n",
    "        # Extract item features for clustering\n",
    "        feature_columns = [col for col in item_data.columns if col != 'item_id']\n",
    "        self.item_features = item_data[feature_columns].values\n",
    "        self.item_id_map = {id: idx for idx, id in enumerate(item_data['item_id'])}\n",
    "        self.idx_to_item_id = {idx: id for id, idx in self.item_id_map.items()}\n",
    "        \n",
    "        # Create user-item interaction matrix\n",
    "        self.create_interaction_matrix()\n",
    "        print(f\"Loaded data: {len(self.all_users)} users, {len(self.all_items)} items, {len(interactions)} interactions\")\n",
    "\n",
    "    def create_interaction_matrix(self):\n",
    "        \"\"\"Create the user-item interaction matrix from interaction data.\"\"\"\n",
    "        # Create user and item ID mappings\n",
    "        self.user_id_map = {id: idx for idx, id in enumerate(self.user_data['user_id'])}\n",
    "        self.idx_to_user_id = {idx: id for id, idx in self.user_id_map.items()}\n",
    "        \n",
    "        # Initialize interaction matrix\n",
    "        num_users = len(self.user_id_map)\n",
    "        num_items = len(self.item_id_map)\n",
    "        self.interaction_matrix = np.zeros((num_users, num_items))\n",
    "        \n",
    "        # Fill the interaction matrix\n",
    "        for _, row in self.interactions.iterrows():\n",
    "            user_idx = self.user_id_map.get(row['user_id'])\n",
    "            item_idx = self.item_id_map.get(row['item_id'])\n",
    "            if user_idx is not None and item_idx is not None:\n",
    "                # For implicit feedback, use 1 to indicate interaction\n",
    "                self.interaction_matrix[user_idx, item_idx] = 1\n",
    "        \n",
    "        print(f\"Created interaction matrix of shape {self.interaction_matrix.shape}\")\n",
    "\n",
    "    def cluster_items(self):\n",
    "        \"\"\"Cluster items based on their features.\"\"\"\n",
    "        print(f\"Clustering {len(self.item_features)} items into {self.num_clusters} clusters...\")\n",
    "        \n",
    "        # Apply k-means clustering\n",
    "        self.clusters = KMeans(n_clusters=self.num_clusters, random_state=42)\n",
    "        self.cluster_assignments = self.clusters.fit_predict(self.item_features)\n",
    "        \n",
    "        # Group items by cluster\n",
    "        self.items_by_cluster = {}\n",
    "        for idx, cluster_id in enumerate(self.cluster_assignments):\n",
    "            if cluster_id not in self.items_by_cluster:\n",
    "                self.items_by_cluster[cluster_id] = []\n",
    "            self.items_by_cluster[cluster_id].append(idx)\n",
    "        \n",
    "        # Create user-cluster interaction matrix\n",
    "        self.create_user_cluster_matrix()\n",
    "        \n",
    "        print(f\"Item clustering complete. Cluster distribution:\")\n",
    "        for cluster_id, items in self.items_by_cluster.items():\n",
    "            print(f\"Cluster {cluster_id}: {len(items)} items\")\n",
    "\n",
    "    def create_user_cluster_matrix(self):\n",
    "        \"\"\"\n",
    "        Create user-cluster interaction matrix by aggregating \n",
    "        user-item interactions within each cluster.\n",
    "        \"\"\"\n",
    "        num_users = self.interaction_matrix.shape[0]\n",
    "        self.user_cluster_matrix = np.zeros((num_users, self.num_clusters))\n",
    "        \n",
    "        # For each user-cluster pair, aggregate interactions\n",
    "        for user_idx in range(num_users):\n",
    "            for cluster_id in range(self.num_clusters):\n",
    "                # Get items in this cluster\n",
    "                cluster_items = self.items_by_cluster[cluster_id]\n",
    "                # Sum interactions with items in this cluster\n",
    "                cluster_interactions = sum(self.interaction_matrix[user_idx, item_idx] for item_idx in cluster_items)\n",
    "                # Normalize by cluster size to get average interaction\n",
    "                self.user_cluster_matrix[user_idx, cluster_id] = cluster_interactions / max(1, len(cluster_items))\n",
    "        \n",
    "        print(f\"Created user-cluster matrix of shape {self.user_cluster_matrix.shape}\")\n",
    "\n",
    "    def matrix_factorization(self):\n",
    "        \"\"\"\n",
    "        Perform hallucination-aware matrix factorization to learn\n",
    "        user and item latent factors.\n",
    "        \"\"\"\n",
    "        print(\"Starting hallucination-aware matrix factorization...\")\n",
    "        \n",
    "        # Initialize user and item embeddings randomly\n",
    "        num_users = self.interaction_matrix.shape[0]\n",
    "        num_items = self.interaction_matrix.shape[1]\n",
    "        \n",
    "        # Initialize embeddings\n",
    "        self.user_embeddings = np.random.normal(0, 0.1, (num_users, self.latent_dim))\n",
    "        self.item_embeddings = np.random.normal(0, 0.1, (num_items, self.latent_dim))\n",
    "        \n",
    "        # Initialize hallucination likelihood scores\n",
    "        # Initially, all items have equal hallucination likelihood\n",
    "        self.hallucination_scores = np.ones((num_users, num_items)) * 0.5\n",
    "        \n",
    "        # Get user-item pairs with observed interactions\n",
    "        user_indices, item_indices = np.where(self.interaction_matrix > 0)\n",
    "        \n",
    "        # Prepare for optimization\n",
    "        learning_rate = self.learning_rate\n",
    "        \n",
    "        # Implement mini-batch SGD as described in Algorithm 1 of the paper\n",
    "        for iteration in range(self.max_iterations):\n",
    "            # Shuffle the observed interactions\n",
    "            indices = np.arange(len(user_indices))\n",
    "            np.random.shuffle(indices)\n",
    "            \n",
    "            # Mini-batch size\n",
    "            batch_size = min(1024, len(indices))\n",
    "            \n",
    "            # Process mini-batches\n",
    "            for start in range(0, len(indices), batch_size):\n",
    "                end = min(start + batch_size, len(indices))\n",
    "                batch_indices = indices[start:end]\n",
    "                \n",
    "                # Get user and item indices for this batch\n",
    "                batch_user_indices = user_indices[batch_indices]\n",
    "                batch_item_indices = item_indices[batch_indices]\n",
    "                \n",
    "                # Update user embeddings\n",
    "                for i, user_idx in enumerate(batch_user_indices):\n",
    "                    item_idx = batch_item_indices[i]\n",
    "                    \n",
    "                    # Get observed interaction\n",
    "                    rating = self.interaction_matrix[user_idx, item_idx]\n",
    "                    \n",
    "                    # Compute prediction\n",
    "                    prediction = np.dot(self.user_embeddings[user_idx], self.item_embeddings[item_idx])\n",
    "                    \n",
    "                    # Compute error\n",
    "                    error = rating - prediction\n",
    "                    \n",
    "                    # Hallucination penalty term (from equation 22 in the paper)\n",
    "                    h_penalty = self.lambda_h * self.hallucination_scores[user_idx, item_idx] * prediction\n",
    "                    \n",
    "                    # Compute gradients\n",
    "                    user_grad = -error * self.item_embeddings[item_idx] + self.lambda_u * self.user_embeddings[user_idx] + h_penalty * self.item_embeddings[item_idx]\n",
    "                    item_grad = -error * self.user_embeddings[user_idx] + self.lambda_v * self.item_embeddings[item_idx] + h_penalty * self.user_embeddings[user_idx]\n",
    "                    \n",
    "                    # Update embeddings\n",
    "                    self.user_embeddings[user_idx] -= learning_rate * user_grad\n",
    "                    self.item_embeddings[item_idx] -= learning_rate * item_grad\n",
    "            \n",
    "            # Decay learning rate (equation 27 in the paper)\n",
    "            learning_rate = self.learning_rate / (1 + self.decay_rate * iteration)\n",
    "            \n",
    "            # Print progress every 10 iterations\n",
    "            if (iteration + 1) % 10 == 0:\n",
    "                # Compute training error\n",
    "                error = self.compute_training_error()\n",
    "                print(f\"Iteration {iteration + 1}/{self.max_iterations}, Error: {error:.4f}, Learning Rate: {learning_rate:.6f}\")\n",
    "        \n",
    "        print(\"Matrix factorization complete\")\n",
    "\n",
    "    def compute_training_error(self):\n",
    "        \"\"\"Compute the training error of the current matrix factorization model.\"\"\"\n",
    "        # Compute predictions for all observed interactions\n",
    "        user_indices, item_indices = np.where(self.interaction_matrix > 0)\n",
    "        ratings = self.interaction_matrix[user_indices, item_indices]\n",
    "        \n",
    "        # Compute predictions\n",
    "        predictions = np.sum(self.user_embeddings[user_indices] * self.item_embeddings[item_indices], axis=1)\n",
    "        \n",
    "        # Compute mean squared error\n",
    "        mse = np.mean((ratings - predictions) ** 2)\n",
    "        return mse\n",
    "\n",
    "    def initialize_agents(self):\n",
    "        \"\"\"Initialize generative agents for each user.\"\"\"\n",
    "        print(\"Initializing generative agents...\")\n",
    "        \n",
    "        for user_id, user_idx in self.user_id_map.items():\n",
    "            # Get user data\n",
    "            user_row = self.user_data[self.user_data['user_id'] == user_id].iloc[0]\n",
    "            \n",
    "            # Extract user traits from user data\n",
    "            traits = {}\n",
    "            for col in self.user_data.columns:\n",
    "                if col != 'user_id':\n",
    "                    traits[col] = user_row[col]\n",
    "            \n",
    "            # Format traits as a string\n",
    "            traits_str = \", \".join([f\"{k}: {v}\" for k, v in traits.items()])\n",
    "            \n",
    "            # Create agent memory\n",
    "            memory = GenerativeAgentMemory(\n",
    "                llm=LLM,\n",
    "                memory_retriever=create_new_memory_retriever(),\n",
    "                verbose=False,\n",
    "                reflection_threshold=30,\n",
    "            )\n",
    "            \n",
    "            # Create generative agent\n",
    "            agent = GenerativeAgent(\n",
    "                name=f\"User_{user_id}\",\n",
    "                age=traits.get('age', 30),  # Default to 30 if age not provided\n",
    "                traits=traits_str,\n",
    "                status=\"looking for recommendations\",\n",
    "                memory_retriever=create_new_memory_retriever(),\n",
    "                llm=LLM,\n",
    "                memory=memory,\n",
    "            )\n",
    "            \n",
    "            # Store agent\n",
    "            self.agents[user_id] = agent\n",
    "            \n",
    "            # Add user interactions as memories to the agent\n",
    "            user_interactions = self.interactions[self.interactions['user_id'] == user_id]\n",
    "            for _, interaction in user_interactions.iterrows():\n",
    "                item_id = interaction['item_id']\n",
    "                if 'timestamp' in interaction:\n",
    "                    timestamp = interaction['timestamp']\n",
    "                    created_at = datetime.fromtimestamp(timestamp) if isinstance(timestamp, (int, float)) else datetime.now()\n",
    "                else:\n",
    "                    created_at = datetime.now()\n",
    "                \n",
    "                # Get item details\n",
    "                item_row = self.item_data[self.item_data['item_id'] == item_id]\n",
    "                if not item_row.empty:\n",
    "                    item_name = item_row.iloc[0].get('name', f\"Item_{item_id}\")\n",
    "                    memory_content = f\"I interacted with {item_name} (ID: {item_id})\"\n",
    "                    \n",
    "                    # Add to agent memory\n",
    "                    agent.memory.add_memory(memory_content)\n",
    "        \n",
    "        print(f\"Initialized {len(self.agents)} generative agents\")\n",
    "\n",
    "    def construct_rag_query(self, user_id):\n",
    "        \"\"\"\n",
    "        Construct a retrieval query integrating user traits and memory.\n",
    "        This implements equation 12 from the paper.\n",
    "        \"\"\"\n",
    "        # Get agent for the user\n",
    "        agent = self.agents[user_id]\n",
    "        \n",
    "        # Get user traits\n",
    "        user_traits = agent.traits\n",
    "        \n",
    "        # Get relevant memories\n",
    "        relevant_memories = agent.memory.memory_retriever.get_relevant_documents(\"What do I like?\")\n",
    "        memory_contents = \" \".join([mem.page_content for mem in relevant_memories])\n",
    "        \n",
    "        # Construct the query\n",
    "        query = f\"User traits: {user_traits}. User memories: {memory_contents}\"\n",
    "        \n",
    "        # Encode the query\n",
    "        query_embedding = embeddings_model.embed_query(query)\n",
    "        \n",
    "        return query, query_embedding\n",
    "\n",
    "    def construct_knowledge_base(self, user_id):\n",
    "        \"\"\"\n",
    "        Construct a knowledge base of relevant items for the user.\n",
    "        This implements equation 14 from the paper.\n",
    "        \"\"\"\n",
    "        # Get user index\n",
    "        user_idx = self.user_id_map[user_id]\n",
    "        \n",
    "        # Predict user's cluster preferences\n",
    "        cluster_scores = np.dot(self.user_embeddings[user_idx], self.item_embeddings.T)\n",
    "        \n",
    "        # Get the top cluster\n",
    "        top_cluster = np.argmax(np.mean([cluster_scores[user_idx] for user_idx in self.items_by_cluster[cluster_id]]) \n",
    "                                for cluster_id in range(self.num_clusters))\n",
    "        \n",
    "        # Get items in the top cluster\n",
    "        cluster_items = self.items_by_cluster[top_cluster]\n",
    "        \n",
    "        # Get item scores\n",
    "        item_scores = np.dot(self.user_embeddings[user_idx], self.item_embeddings[cluster_items].T)\n",
    "        \n",
    "        # Filter items by relevance threshold\n",
    "        relevant_items = [cluster_items[i] for i, score in enumerate(item_scores) if score >= self.relevance_threshold]\n",
    "        \n",
    "        # Create knowledge base with item details\n",
    "        knowledge_base = []\n",
    "        for item_idx in relevant_items:\n",
    "            item_id = self.idx_to_item_id[item_idx]\n",
    "            item_row = self.item_data[self.item_data['item_id'] == item_id]\n",
    "            if not item_row.empty:\n",
    "                item_info = {}\n",
    "                for col in item_row.columns:\n",
    "                    item_info[col] = item_row.iloc[0][col]\n",
    "                knowledge_base.append(item_info)\n",
    "        \n",
    "        return knowledge_base, top_cluster\n",
    "\n",
    "    def retrieve_items(self, user_id, query_embedding, knowledge_base):\n",
    "        \"\"\"\n",
    "        Retrieve items from the knowledge base based on similarity to query.\n",
    "        This implements equation 15 from the paper.\n",
    "        \"\"\"\n",
    "        # Encode each item in the knowledge base\n",
    "        item_embeddings = []\n",
    "        for item in knowledge_base:\n",
    "            # Convert item to string representation\n",
    "            item_str = \", \".join([f\"{k}: {v}\" for k, v in item.items() if k != 'item_id'])\n",
    "            item_embedding = embeddings_model.embed_query(item_str)\n",
    "            item_embeddings.append((item, item_embedding))\n",
    "        \n",
    "        # Compute similarities\n",
    "        similarities = []\n",
    "        for item, item_embedding in item_embeddings:\n",
    "            sim = cosine_similarity([query_embedding], [item_embedding])[0][0]\n",
    "            similarities.append((item, sim))\n",
    "        \n",
    "        # Sort by similarity and filter by threshold\n",
    "        retrieved_items = [item for item, sim in sorted(similarities, key=lambda x: x[1], reverse=True) \n",
    "                          if sim >= self.similarity_threshold]\n",
    "        \n",
    "        return retrieved_items\n",
    "\n",
    "    def generate_recommendations(self, user_id, num_recommendations=5):\n",
    "        \"\"\"\n",
    "        Generate recommendations for a user using the HallAgent4Rec methodology.\n",
    "        This implements the full recommendation pipeline from the paper.\n",
    "        \"\"\"\n",
    "        print(f\"Generating recommendations for user {user_id}...\")\n",
    "        \n",
    "        # Step 1: Construct RAG query (eq. 12-13)\n",
    "        query, query_embedding = self.construct_rag_query(user_id)\n",
    "        \n",
    "        # Step 2: Construct knowledge base (eq. 14)\n",
    "        knowledge_base, top_cluster = self.construct_knowledge_base(user_id)\n",
    "        \n",
    "        # Step 3: Retrieve relevant items (eq. 15)\n",
    "        retrieved_items = self.retrieve_items(user_id, query_embedding, knowledge_base)\n",
    "        \n",
    "        # If no items retrieved, return empty list\n",
    "        if not retrieved_items:\n",
    "            print(\"No relevant items retrieved. Cannot generate recommendations.\")\n",
    "            return []\n",
    "        \n",
    "        # Step 4: Generate recommendations using LLM\n",
    "        # Format retrieved items for prompt\n",
    "        item_descriptions = \"\\n\".join([f\"- {item['name']}\" for item in retrieved_items[:10]])\n",
    "        \n",
    "        # Get agent\n",
    "        agent = self.agents[user_id]\n",
    "        \n",
    "        # Create prompt for LLM\n",
    "        prompt = f\"\"\"\n",
    "        You are a recommendation system for a user with the following traits:\n",
    "        {agent.traits}\n",
    "        \n",
    "        Based on the user's profile and past behavior, you have retrieved the following relevant items:\n",
    "        {item_descriptions}\n",
    "        \n",
    "        Please recommend {num_recommendations} items from the list above that would be most relevant for this user.\n",
    "        For each recommendation, provide a brief explanation of why it matches the user's preferences.\n",
    "        \n",
    "        IMPORTANT: You must ONLY recommend items from the provided list. Do not suggest any items that are not in the list.\n",
    "        \n",
    "        Format your response as:\n",
    "        1. [Item Name]: [Explanation]\n",
    "        2. [Item Name]: [Explanation]\n",
    "        ...\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate recommendations\n",
    "        response = LLM.invoke(prompt)\n",
    "        recommendations_text = response.content\n",
    "        \n",
    "        # Step 5: Detect hallucinations\n",
    "        # Extract recommended items from response\n",
    "        recommended_items = []\n",
    "        lines = recommendations_text.strip().split('\\n')\n",
    "        for line in lines:\n",
    "            if line.strip() and any(char.isdigit() for char in line[:5]):\n",
    "                # Extract item name from line (format: \"1. [Item Name]: [Explanation]\")\n",
    "                parts = line.split(':', 1)\n",
    "                if len(parts) > 0:\n",
    "                    item_name_part = parts[0].strip()\n",
    "                    # Extract text inside brackets if present\n",
    "                    item_name = item_name_part.split('.', 1)[1].strip() if '.' in item_name_part else item_name_part\n",
    "                    recommended_items.append(item_name)\n",
    "        \n",
    "        # Check for hallucinations (items not in retrieved set)\n",
    "        retrieved_item_names = [item['name'] for item in retrieved_items]\n",
    "        hallucinations = []\n",
    "        valid_recommendations = []\n",
    "        \n",
    "        for item_name in recommended_items:\n",
    "            is_hallucination = True\n",
    "            # Check if recommended item is in retrieved items (allowing for minor text differences)\n",
    "            for retrieved_name in retrieved_item_names:\n",
    "                print(\"item_name: \", item_name)\n",
    "                print(\"retrieved_name: \", retrieved_name)\n",
    "                if item_name == retrieved_name:\n",
    "                    is_hallucination = False\n",
    "                    # Find the actual item\n",
    "                    for item in retrieved_items:\n",
    "                        if item['name'] == item_name:\n",
    "                            valid_recommendations.append(item)\n",
    "                            break\n",
    "                    break\n",
    "            \n",
    "            if is_hallucination:\n",
    "                hallucinations.append(item_name)\n",
    "        \n",
    "        # Report hallucinations\n",
    "        if hallucinations:\n",
    "            print(f\"Detected {len(hallucinations)} hallucinations: {hallucinations}\")\n",
    "            \n",
    "            # Update hallucination scores\n",
    "            user_idx = self.user_id_map[user_id]\n",
    "            for hallucination in hallucinations:\n",
    "                # For each hallucination, increase hallucination scores for similar items\n",
    "                for item_idx in range(self.item_embeddings.shape[0]):\n",
    "                    item_id = self.idx_to_item_id[item_idx]\n",
    "                    item_row = self.item_data[self.item_data['item_id'] == item_id]\n",
    "                    if not item_row.empty:\n",
    "                        item_name = item_row.iloc[0].get('name', f\"Item_{item_id}\")\n",
    "                        # If item name is similar to hallucination, increase score\n",
    "                        if hallucination==item_name:\n",
    "                            self.hallucination_scores[user_idx, item_idx] += 0.1\n",
    "        \n",
    "        # If not enough valid recommendations, fill with top predicted items\n",
    "        if len(valid_recommendations) < num_recommendations:\n",
    "            user_idx = self.user_id_map[user_id]\n",
    "            cluster_items = self.items_by_cluster[top_cluster]\n",
    "            \n",
    "            # Get predicted scores for items in the cluster\n",
    "            item_scores = [(idx, np.dot(self.user_embeddings[user_idx], self.item_embeddings[idx])) \n",
    "                           for idx in cluster_items]\n",
    "            \n",
    "            # Sort by score and remove items already recommended\n",
    "            recommended_ids = [item['item_id'] for item in valid_recommendations]\n",
    "            additional_items = []\n",
    "            \n",
    "            for item_idx, score in sorted(item_scores, key=lambda x: x[1], reverse=True):\n",
    "                item_id = self.idx_to_item_id[item_idx]\n",
    "                if item_id not in recommended_ids:\n",
    "                    item_row = self.item_data[self.item_data['item_id'] == item_id]\n",
    "                    if not item_row.empty:\n",
    "                        item_info = {}\n",
    "                        for col in item_row.columns:\n",
    "                            item_info[col] = item_row.iloc[0][col]\n",
    "                        additional_items.append(item_info)\n",
    "                        if len(valid_recommendations) + len(additional_items) >= num_recommendations:\n",
    "                            break\n",
    "            \n",
    "            valid_recommendations.extend(additional_items)\n",
    "        \n",
    "        # Limit to requested number\n",
    "        valid_recommendations = valid_recommendations[:num_recommendations]\n",
    "        \n",
    "        print(f\"Generated {len(valid_recommendations)} valid recommendations\")\n",
    "        return valid_recommendations\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Train the complete HallAgent4Rec model.\"\"\"\n",
    "        # Step 1: Cluster items\n",
    "        self.cluster_items()\n",
    "        \n",
    "        # Step 2: Initialize matrix factorization\n",
    "        self.matrix_factorization()\n",
    "        \n",
    "        # Step 3: Initialize generative agents\n",
    "        self.initialize_agents()\n",
    "        \n",
    "        print(\"HallAgent4Rec training complete!\")\n",
    "\n",
    "    def evaluate(self, test_interactions, metrics=['precision', 'recall', 'hallucination_rate']):\n",
    "        \"\"\"\n",
    "        Evaluate the recommendation system using test interactions.\n",
    "        \n",
    "        Args:\n",
    "            test_interactions: DataFrame with test user-item interactions\n",
    "            metrics: List of metrics to compute\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary of evaluation metrics\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        if 'precision' in metrics or 'recall' in metrics:\n",
    "            # Group test interactions by user\n",
    "            user_test_items = {}\n",
    "            for _, row in test_interactions.iterrows():\n",
    "                user_id = row['user_id']\n",
    "                item_id = row['item_id']\n",
    "                if user_id not in user_test_items:\n",
    "                    user_test_items[user_id] = set()\n",
    "                user_test_items[user_id].add(item_id)\n",
    "            \n",
    "            # Generate recommendations for each user\n",
    "            precision_sum = 0\n",
    "            recall_sum = 0\n",
    "            user_count = 0\n",
    "            \n",
    "            for user_id, test_items in user_test_items.items():\n",
    "                if user_id in self.user_id_map:\n",
    "                    # Generate recommendations\n",
    "                    recommendations = self.generate_recommendations(user_id, num_recommendations=10)\n",
    "                    if recommendations:\n",
    "                        recommended_items = [item['item_id'] for item in recommendations]\n",
    "                        \n",
    "                        # Compute precision and recall\n",
    "                        hit_count = len(set(recommended_items) & test_items)\n",
    "                        precision = hit_count / len(recommended_items) if recommended_items else 0\n",
    "                        recall = hit_count / len(test_items) if test_items else 0\n",
    "                        \n",
    "                        precision_sum += precision\n",
    "                        recall_sum += recall\n",
    "                        user_count += 1\n",
    "            \n",
    "            # Compute average precision and recall\n",
    "            if user_count > 0:\n",
    "                results['precision'] = precision_sum / user_count\n",
    "                results['recall'] = recall_sum / user_count\n",
    "        \n",
    "        if 'hallucination_rate' in metrics:\n",
    "            # Evaluate hallucination rate on a sample of users\n",
    "            hallucination_count = 0\n",
    "            total_recommendations = 0\n",
    "            \n",
    "            sample_users = np.random.choice(list(self.user_id_map.keys()), \n",
    "                                           size=min(50, len(self.user_id_map)), \n",
    "                                           replace=False)\n",
    "            \n",
    "            for user_id in sample_users:\n",
    "                # Construct query and knowledge base\n",
    "                query, query_embedding = self.construct_rag_query(user_id)\n",
    "                knowledge_base, _ = self.construct_knowledge_base(user_id)\n",
    "                retrieved_items = self.retrieve_items(user_id, query_embedding, knowledge_base)\n",
    "                \n",
    "                # Format retrieved items for prompt\n",
    "                item_descriptions = \"\\n\".join([f\"- {item['name']}\" for item in retrieved_items[:10]])\n",
    "                \n",
    "                # Get agent\n",
    "                agent = self.agents[user_id]\n",
    "                \n",
    "                # Create prompt for LLM\n",
    "                prompt = f\"\"\"\n",
    "                You are a recommendation system for a user with the following traits:\n",
    "                {agent.traits}\n",
    "                \n",
    "                Based on the user's profile and past behavior, you have retrieved the following relevant items:\n",
    "                {item_descriptions}\n",
    "                \n",
    "                Please recommend 5 items from the list above that would be most relevant for this user.\n",
    "                Provide a brief explanation for each recommendation.\n",
    "                \n",
    "                IMPORTANT: You must ONLY recommend items from the provided list. Do not suggest any items that are not in the list.\n",
    "                \n",
    "                Format your response as:\n",
    "                1. [Item Name]: [Explanation]\n",
    "                2. [Item Name]: [Explanation]\n",
    "                ...\n",
    "                \"\"\"\n",
    "                \n",
    "                # Generate recommendations\n",
    "                response = LLM.invoke(prompt)\n",
    "                recommendations_text = response.content\n",
    "                \n",
    "                # Extract recommended items from response\n",
    "                recommended_items = []\n",
    "                lines = recommendations_text.strip().split('\\n')\n",
    "                for line in lines:\n",
    "                    if line.strip() and any(char.isdigit() for char in line[:5]):\n",
    "                        parts = line.split(':', 1)\n",
    "                        if len(parts) > 0:\n",
    "                            item_name_part = parts[0].strip()\n",
    "                            item_name = item_name_part.split('.', 1)[1].strip() if '.' in item_name_part else item_name_part\n",
    "                            recommended_items.append(item_name)\n",
    "                \n",
    "                # Check for hallucinations\n",
    "                retrieved_item_names = [item['name'] for item in retrieved_items]\n",
    "                for item_name in recommended_items:\n",
    "                    total_recommendations += 1\n",
    "                    is_hallucination = True\n",
    "                    for retrieved_name in retrieved_item_names:\n",
    "                        if item_name == retrieved_name:\n",
    "                            is_hallucination = False\n",
    "                            break\n",
    "                    \n",
    "                    if is_hallucination:\n",
    "                        hallucination_count += 1\n",
    "            \n",
    "            # Compute hallucination rate\n",
    "            if total_recommendations > 0:\n",
    "                results['hallucination_rate'] = hallucination_count / total_recommendations\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "def example_usage():\n",
    "    # Create sample data\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    # User data\n",
    "    user_data = pd.DataFrame({\n",
    "        'user_id': [1, 2, 3, 4, 5],\n",
    "        'age': [25, 30, 35, 40, 45],\n",
    "        'gender': ['M', 'F', 'M', 'F', 'M'],\n",
    "        'occupation': ['student', 'engineer', 'doctor', 'artist', 'teacher']\n",
    "    })\n",
    "    \n",
    "    # Item data\n",
    "    item_data = pd.DataFrame({\n",
    "        'item_id': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
    "        'name': ['Item A', 'Item B', 'Item C', 'Item D', 'Item E', \n",
    "                 'Item F', 'Item G', 'Item H', 'Item I', 'Item J'],\n",
    "        'category': ['books', 'electronics', 'books', 'clothing', 'electronics',\n",
    "                    'books', 'clothing', 'electronics', 'books', 'clothing'],\n",
    "        'price': [10, 50, 15, 30, 100, 20, 25, 80, 12, 35],\n",
    "        'popularity': [0.8, 0.6, 0.9, 0.7, 0.5, 0.4, 0.7, 0.6, 0.3, 0.8]\n",
    "    })\n",
    "    label_encoders = {}\n",
    "    for col in ['gender', 'occupation']:\n",
    "        le = LabelEncoder()\n",
    "        user_data[col] = le.fit_transform(user_data[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    for col in ['category','name']:\n",
    "        le = LabelEncoder()\n",
    "        item_data[col] = le.fit_transform(item_data[col])\n",
    "        label_encoders[col] = le\n",
    "    print(item_data.head(2))\n",
    "    # Interaction data\n",
    "    interactions = pd.DataFrame({\n",
    "        'user_id': [1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 5],\n",
    "        'item_id': [101, 103, 105, 102, 104, 103, 106, 109, 105, 107, 101, 108, 110],\n",
    "        'timestamp': [1615000000, 1615100000, 1615200000, 1615300000, 1615400000,\n",
    "                     1615500000, 1615600000, 1615700000, 1615800000, 1615900000,\n",
    "                     1616000000, 1616100000, 1616200000]\n",
    "    })\n",
    "    \n",
    "    # Test interactions\n",
    "    test_interactions = pd.DataFrame({\n",
    "        'user_id': [1, 2, 3, 4, 5],\n",
    "        'item_id': [106, 101, 102, 108, 103]\n",
    "    })\n",
    "    \n",
    "    # Initialize HallAgent4Rec\n",
    "    hall_agent = HallAgent4Rec(num_clusters=3, latent_dim=10)\n",
    "    \n",
    "    # Load data\n",
    "    hall_agent.load_data(user_data, item_data, interactions)\n",
    "    \n",
    "    # Train the system\n",
    "    hall_agent.train()\n",
    "    \n",
    "    # Generate recommendations for a user\n",
    "    recommendations = hall_agent.generate_recommendations(user_id=1, num_recommendations=3)\n",
    "    print(\"Recommendations for User 1:\")\n",
    "    for i, item in enumerate(recommendations):\n",
    "        print(f\"{i+1}. {item['name']} - {item['category']} (${item['price']})\")\n",
    "    \n",
    "    # Evaluate the system\n",
    "    eval_results = hall_agent.evaluate(test_interactions)\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    for metric, value in eval_results.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    example_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedClusterHallAgent4Rec(HallAgent4Rec):\n",
    "    def __init__(self, num_user_clusters=10, personalization_weight=0.7, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize with enhanced user clustering that preserves personalization.\n",
    "        \n",
    "        Args:\n",
    "            num_user_clusters: Number of user clusters to create\n",
    "            personalization_weight: Weight given to user-specific preferences vs. cluster preferences\n",
    "                                    (higher = more personalized, range 0-1)\n",
    "            **kwargs: Other parameters for HallAgent4Rec\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_user_clusters = num_user_clusters\n",
    "        self.user_cluster_model = None\n",
    "        self.user_cluster_assignments = None\n",
    "        self.cluster_agents = {}  # Maps cluster_id -> agent\n",
    "        self.user_to_cluster = {}  # Maps user_id -> cluster_id\n",
    "        self.personalization_weight = personalization_weight\n",
    "        self.cluster_item_ratings = {}  # Average ratings per cluster for each item\n",
    "    \n",
    "    def cluster_users(self):\n",
    "        \"\"\"Cluster users based on their interaction patterns and traits.\"\"\"\n",
    "        print(f\"Clustering {len(self.user_data)} users into {self.num_user_clusters} clusters...\")\n",
    "        \n",
    "        # Create user feature matrix\n",
    "        user_features = []\n",
    "        \n",
    "        # 1. Incorporate interaction patterns\n",
    "        for user_id in self.user_data['user_id']:\n",
    "            user_idx = self.user_id_map[user_id]\n",
    "            # Get user's item interaction vector\n",
    "            interaction_vector = self.interaction_matrix[user_idx]\n",
    "            \n",
    "            # 2. If user data contains demographic features, add them\n",
    "            user_row = self.user_data[self.user_data['user_id'] == user_id].iloc[0]\n",
    "            demographic_features = []\n",
    "            \n",
    "            for col in self.user_data.columns:\n",
    "                if col != 'user_id':\n",
    "                    # Convert categorical features to numeric if needed\n",
    "                    val = user_row[col]\n",
    "                    if isinstance(val, (str)):\n",
    "                        continue  # Skip categorical for simplicity\n",
    "                    if isinstance(val, (int, float)):\n",
    "                        demographic_features.append(val)\n",
    "            \n",
    "            # Combine interaction and demographic features\n",
    "            # You might want to normalize these features or apply weights\n",
    "            combined_features = np.concatenate([interaction_vector, demographic_features])\n",
    "            user_features.append(combined_features)\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        user_features = np.array(user_features)\n",
    "        \n",
    "        # Fill NaN values with 0\n",
    "        user_features = np.nan_to_num(user_features)\n",
    "        \n",
    "        # Apply k-means clustering to users\n",
    "        self.user_cluster_model = KMeans(n_clusters=self.num_user_clusters, random_state=42)\n",
    "        self.user_cluster_assignments = self.user_cluster_model.fit_predict(user_features)\n",
    "        \n",
    "        # Map users to clusters\n",
    "        for i, user_id in enumerate(self.user_data['user_id']):\n",
    "            cluster_id = self.user_cluster_assignments[i]\n",
    "            self.user_to_cluster[user_id] = cluster_id\n",
    "        \n",
    "        print(f\"User clustering complete. Cluster distribution:\")\n",
    "        cluster_counts = {}\n",
    "        for cluster_id in range(self.num_user_clusters):\n",
    "            count = sum(1 for cid in self.user_cluster_assignments if cid == cluster_id)\n",
    "            cluster_counts[cluster_id] = count\n",
    "            print(f\"Cluster {cluster_id}: {count} users\")\n",
    "            \n",
    "        # Compute cluster-level item ratings\n",
    "        self.compute_cluster_item_ratings()\n",
    "    \n",
    "    def compute_cluster_item_ratings(self):\n",
    "        \"\"\"\n",
    "        Compute average item ratings for each cluster.\n",
    "        These act as a starting point that will be personalized for each user.\n",
    "        \"\"\"\n",
    "        print(\"Computing cluster-level item ratings...\")\n",
    "        \n",
    "        for cluster_id in range(self.num_user_clusters):\n",
    "            # Get users in this cluster\n",
    "            cluster_users = [self.user_id_map[user_id] for user_id, cid in self.user_to_cluster.items() \n",
    "                            if cid == cluster_id and user_id in self.user_id_map]\n",
    "            \n",
    "            if not cluster_users:\n",
    "                continue\n",
    "            \n",
    "            # Get average interaction matrix for this cluster\n",
    "            cluster_interactions = np.zeros(self.interaction_matrix.shape[1])\n",
    "            for user_idx in cluster_users:\n",
    "                cluster_interactions += self.interaction_matrix[user_idx]\n",
    "            \n",
    "            # Normalize by number of users\n",
    "            cluster_interactions /= len(cluster_users)\n",
    "            \n",
    "            # Store cluster-level ratings\n",
    "            self.cluster_item_ratings[cluster_id] = cluster_interactions\n",
    "    \n",
    "    def initialize_representative_agents(self):\n",
    "        \"\"\"Initialize one agent per user cluster instead of per user.\"\"\"\n",
    "        print(f\"Initializing {self.num_user_clusters} representative agents (instead of {len(self.user_data)} user agents)...\")\n",
    "        \n",
    "        for cluster_id in range(self.num_user_clusters):\n",
    "            # Find users in this cluster\n",
    "            cluster_users = [user_id for user_id, cid in self.user_to_cluster.items() if cid == cluster_id]\n",
    "            \n",
    "            if not cluster_users:\n",
    "                continue\n",
    "                \n",
    "            # Compute average traits and interactions for this cluster\n",
    "            cluster_traits = {}\n",
    "            \n",
    "            # 1. Average numeric traits\n",
    "            numeric_columns = [col for col in self.user_data.columns \n",
    "                              if col != 'user_id' and pd.api.types.is_numeric_dtype(self.user_data[col])]\n",
    "            \n",
    "            for col in numeric_columns:\n",
    "                avg_value = self.user_data[self.user_data['user_id'].isin(cluster_users)][col].mean()\n",
    "                cluster_traits[col] = avg_value\n",
    "            \n",
    "            # 2. Mode for categorical traits\n",
    "            categorical_columns = [col for col in self.user_data.columns \n",
    "                                 if col != 'user_id' and not pd.api.types.is_numeric_dtype(self.user_data[col])]\n",
    "            \n",
    "            for col in categorical_columns:\n",
    "                mode_value = self.user_data[self.user_data['user_id'].isin(cluster_users)][col].mode().iloc[0]\n",
    "                cluster_traits[col] = mode_value\n",
    "            \n",
    "            # Format traits as a string\n",
    "            traits_str = \", \".join([f\"{k}: {v}\" for k, v in cluster_traits.items()])\n",
    "            \n",
    "            # Create agent memory\n",
    "            memory = GenerativeAgentMemory(\n",
    "                llm=LLM,\n",
    "                memory_retriever=create_new_memory_retriever(),\n",
    "                verbose=False,\n",
    "                reflection_threshold=30,\n",
    "            )\n",
    "            \n",
    "            # Create representative generative agent for this cluster\n",
    "            agent = GenerativeAgent(\n",
    "                name=f\"Cluster_{cluster_id}\",\n",
    "                age=int(cluster_traits.get('age', 30)) if 'age' in cluster_traits else 30,\n",
    "                traits=traits_str,\n",
    "                status=\"representing a group of similar users\",\n",
    "                memory_retriever=create_new_memory_retriever(),\n",
    "                llm=LLM,\n",
    "                memory=memory,\n",
    "            )\n",
    "            \n",
    "            # Store the agent\n",
    "            self.cluster_agents[cluster_id] = agent\n",
    "            \n",
    "            # Add representative memories from this cluster\n",
    "            # Take a sample of interactions from users in this cluster\n",
    "            cluster_interactions = self.interactions[self.interactions['user_id'].isin(cluster_users)]\n",
    "            if len(cluster_interactions) > 10:\n",
    "                # Sample up to 10 interactions per cluster to avoid excessive API calls\n",
    "                sampled_interactions = cluster_interactions.sample(10, random_state=42)\n",
    "            else:\n",
    "                sampled_interactions = cluster_interactions\n",
    "                \n",
    "            for _, interaction in sampled_interactions.iterrows():\n",
    "                item_id = interaction['item_id']\n",
    "                if 'timestamp' in interaction:\n",
    "                    timestamp = interaction['timestamp']\n",
    "                    created_at = datetime.fromtimestamp(timestamp) if isinstance(timestamp, (int, float)) else datetime.now()\n",
    "                else:\n",
    "                    created_at = datetime.now()\n",
    "                \n",
    "                # Get item details\n",
    "                item_row = self.item_data[self.item_data['item_id'] == item_id]\n",
    "                if not item_row.empty:\n",
    "                    item_name = item_row.iloc[0].get('name', f\"Item_{item_id}\")\n",
    "                    memory_content = f\"A user in my cluster interacted with {item_name} (ID: {item_id})\"\n",
    "                    \n",
    "                    # Add to agent memory\n",
    "                    agent.memory.add_memory(memory_content)\n",
    "        \n",
    "        print(f\"Initialized {len(self.cluster_agents)} cluster representative agents\")\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Train the modified HallAgent4Rec model with user clustering.\"\"\"\n",
    "        # Step 1: Cluster items (same as original)\n",
    "        self.cluster_items()\n",
    "        \n",
    "        # Step 2: Initialize matrix factorization (same as original)\n",
    "        self.matrix_factorization()\n",
    "        \n",
    "        # Step 3: Cluster users (new step)\n",
    "        self.cluster_users()\n",
    "        \n",
    "        # Step 4: Initialize representative agents (instead of per-user agents)\n",
    "        self.initialize_representative_agents()\n",
    "        \n",
    "        print(\"EnhancedClusterHallAgent4Rec training complete!\")\n",
    "    \n",
    "    def get_personalized_item_scores(self, user_id):\n",
    "        \"\"\"\n",
    "        Calculate personalized item scores by blending:\n",
    "        1. User-specific preferences from matrix factorization\n",
    "        2. Cluster-level preferences\n",
    "        \n",
    "        This demonstrates how personalization is maintained even with shared agents.\n",
    "        \"\"\"\n",
    "        # Get user and cluster info\n",
    "        user_idx = self.user_id_map[user_id]\n",
    "        cluster_id = self.user_to_cluster[user_id]\n",
    "        \n",
    "        # 1. Get user-specific scores from matrix factorization\n",
    "        user_specific_scores = np.dot(self.user_embeddings[user_idx], self.item_embeddings.T)\n",
    "        \n",
    "        # 2. Get cluster-level scores\n",
    "        cluster_scores = self.cluster_item_ratings.get(cluster_id, np.zeros_like(user_specific_scores))\n",
    "        \n",
    "        # 3. Normalize both score arrays to 0-1 range\n",
    "        user_specific_scores = (user_specific_scores - user_specific_scores.min()) / (user_specific_scores.max() - user_specific_scores.min() + 1e-10)\n",
    "        if cluster_scores.max() > cluster_scores.min():\n",
    "            cluster_scores = (cluster_scores - cluster_scores.min()) / (cluster_scores.max() - cluster_scores.min())\n",
    "        \n",
    "        # 4. Blend user-specific and cluster scores using personalization weight\n",
    "        # Higher weight = more emphasis on individual user preferences\n",
    "        blended_scores = (self.personalization_weight * user_specific_scores + \n",
    "                           (1 - self.personalization_weight) * cluster_scores)\n",
    "        \n",
    "        return blended_scores\n",
    "    \n",
    "    def generate_recommendations(self, user_id, num_recommendations=5):\n",
    "        \"\"\"\n",
    "        Generate recommendations for a user using the representative agent for their cluster,\n",
    "        while maintaining personalization through individual user embeddings.\n",
    "        \"\"\"\n",
    "        print(f\"Generating recommendations for user {user_id}...\")\n",
    "        \n",
    "        # Get user's cluster\n",
    "        cluster_id = self.user_to_cluster.get(user_id)\n",
    "        if cluster_id is None:\n",
    "            print(f\"User {user_id} not found in clustering. Cannot generate recommendations.\")\n",
    "            return []\n",
    "        \n",
    "        # Get the representative agent for this cluster\n",
    "        agent = self.cluster_agents.get(cluster_id)\n",
    "        if agent is None:\n",
    "            print(f\"No agent for cluster {cluster_id}. Cannot generate recommendations.\")\n",
    "            return []\n",
    "        \n",
    "        # PERSONALIZATION PART 1: Get user-specific item scores\n",
    "        # This ensures recommendations are personalized even with shared agents\n",
    "        personalized_scores = self.get_personalized_item_scores(user_id)\n",
    "        \n",
    "        # Get user index\n",
    "        user_idx = self.user_id_map[user_id]\n",
    "        \n",
    "        # Step 1: Construct RAG query\n",
    "        # Start with the cluster agent's traits\n",
    "        query = f\"User traits: {agent.traits}.\"\n",
    "        \n",
    "        # PERSONALIZATION PART 2: Add user-specific recent interactions\n",
    "        user_interactions = self.interactions[self.interactions['user_id'] == user_id]\n",
    "        if not user_interactions.empty:\n",
    "            recent_interactions = user_interactions.sort_values('timestamp', ascending=False).head(5)\n",
    "            interaction_texts = []\n",
    "            for _, interaction in recent_interactions.iterrows():\n",
    "                item_id = interaction['item_id']\n",
    "                item_row = self.item_data[self.item_data['item_id'] == item_id]\n",
    "                if not item_row.empty:\n",
    "                    item_name = item_row.iloc[0].get('name', f\"Item_{item_id}\")\n",
    "                    interaction_texts.append(f\"interacted with {item_name}\")\n",
    "            \n",
    "            if interaction_texts:\n",
    "                query += f\" Recent activities: user {', '.join(interaction_texts)}.\"\n",
    "        \n",
    "        # Get query embedding\n",
    "        query_embedding = embeddings_model.embed_query(query)\n",
    "        \n",
    "        # PERSONALIZATION PART 3: User-specific knowledge base\n",
    "        # Instead of using the generic construct_knowledge_base method, we'll create a personalized version\n",
    "        # Get the top cluster based on personalized scores\n",
    "        item_indices = np.argsort(personalized_scores)[::-1][:100]  # Get top 100 items\n",
    "        \n",
    "        # Group these items by their clusters\n",
    "        cluster_item_counts = {}\n",
    "        for item_idx in item_indices:\n",
    "            item_cluster = self.cluster_assignments[item_idx] if item_idx < len(self.cluster_assignments) else 0\n",
    "            cluster_item_counts[item_cluster] = cluster_item_counts.get(item_cluster, 0) + 1\n",
    "        \n",
    "        # Get the top cluster with the most high-scoring items\n",
    "        top_cluster = max(cluster_item_counts.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        # Get items in the top cluster\n",
    "        cluster_items = self.items_by_cluster[top_cluster]\n",
    "        \n",
    "        # PERSONALIZATION PART 4: Filter by personalized relevance\n",
    "        # Filter items by personalized relevance threshold\n",
    "        relevant_items = [item_idx for item_idx in cluster_items \n",
    "                         if personalized_scores[item_idx] >= self.relevance_threshold]\n",
    "        \n",
    "        # Create knowledge base with item details\n",
    "        knowledge_base = []\n",
    "        for item_idx in relevant_items:\n",
    "            item_id = self.idx_to_item_id[item_idx]\n",
    "            item_row = self.item_data[self.item_data['item_id'] == item_id]\n",
    "            if not item_row.empty:\n",
    "                item_info = {}\n",
    "                for col in item_row.columns:\n",
    "                    item_info[col] = item_row.iloc[0][col]\n",
    "                knowledge_base.append(item_info)\n",
    "        \n",
    "        # Perform retrieval on the personalized knowledge base\n",
    "        retrieved_items = self.retrieve_items(user_id, query_embedding, knowledge_base)\n",
    "        \n",
    "        # If no items retrieved, return empty list\n",
    "        if not retrieved_items:\n",
    "            print(\"No relevant items retrieved. Cannot generate recommendations.\")\n",
    "            return []\n",
    "        \n",
    "        # Format retrieved items for prompt\n",
    "        item_descriptions = \"\\n\".join([f\"- {item['name']}\" for item in retrieved_items[:10]])\n",
    "        \n",
    "        # PERSONALIZATION PART 5: Create a prompt that includes user-specific information\n",
    "        # Get user-specific traits to blend with cluster traits\n",
    "        user_row = self.user_data[self.user_data['user_id'] == user_id].iloc[0]\n",
    "        user_specific_traits = \", \".join([f\"{k}: {v}\" for k, v in user_row.items() if k != 'user_id'])\n",
    "        \n",
    "        # Create prompt for LLM that includes both cluster and user-specific information\n",
    "        prompt = f\"\"\"\n",
    "        You are a recommendation system for a user with the following cluster traits:\n",
    "        {agent.traits}\n",
    "        \n",
    "        This specific user has these characteristics:\n",
    "        {user_specific_traits}\n",
    "        \n",
    "        Based on this user's specific profile and past behavior, you have retrieved the following relevant items:\n",
    "        {item_descriptions}\n",
    "        \n",
    "        Please recommend {num_recommendations} items from the list above that would be most relevant for this specific user.\n",
    "        For each recommendation, provide a brief explanation of why it matches the user's preferences.\n",
    "        \n",
    "        IMPORTANT: You must ONLY recommend items from the provided list. Do not suggest any items that are not in the list.\n",
    "        \n",
    "        Format your response as:\n",
    "        1. [Item Name]: [Explanation]\n",
    "        2. [Item Name]: [Explanation]\n",
    "        ...\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate recommendations\n",
    "        response = LLM.invoke(prompt)\n",
    "        recommendations_text = response.content\n",
    "        \n",
    "        # Extract recommended items and check for hallucinations\n",
    "        recommended_items = []\n",
    "        lines = recommendations_text.strip().split('\\n')\n",
    "        for line in lines:\n",
    "            if line.strip() and any(char.isdigit() for char in line[:5]):\n",
    "                parts = line.split(':', 1)\n",
    "                if len(parts) > 0:\n",
    "                    item_name_part = parts[0].strip()\n",
    "                    item_name = item_name_part.split('.', 1)[1].strip() if '.' in item_name_part else item_name_part\n",
    "                    recommended_items.append(item_name)\n",
    "        \n",
    "        # Check for hallucinations (items not in retrieved set)\n",
    "        retrieved_item_names = [item['name'] for item in retrieved_items]\n",
    "        hallucinations = []\n",
    "        valid_recommendations = []\n",
    "        \n",
    "        for item_name in recommended_items:\n",
    "            is_hallucination = True\n",
    "            for retrieved_name in retrieved_item_names:\n",
    "                if item_name == retrieved_name:\n",
    "                    is_hallucination = False\n",
    "                    for item in retrieved_items:\n",
    "                        if item['name'] == item_name:\n",
    "                            valid_recommendations.append(item)\n",
    "                            break\n",
    "                    break\n",
    "            \n",
    "            if is_hallucination:\n",
    "                hallucinations.append(item_name)\n",
    "        \n",
    "        # PERSONALIZATION PART 6: Fill with top personalized items if needed\n",
    "        if len(valid_recommendations) < num_recommendations:\n",
    "            # Get top items based on personalized scores\n",
    "            top_item_indices = np.argsort(personalized_scores)[::-1]\n",
    "            \n",
    "            # Add additional items\n",
    "            recommended_ids = [item['item_id'] for item in valid_recommendations]\n",
    "            additional_items = []\n",
    "            \n",
    "            for item_idx in top_item_indices:\n",
    "                if item_idx >= len(self.idx_to_item_id):\n",
    "                    continue\n",
    "                    \n",
    "                item_id = self.idx_to_item_id[item_idx]\n",
    "                if item_id not in recommended_ids:\n",
    "                    item_row = self.item_data[self.item_data['item_id'] == item_id]\n",
    "                    if not item_row.empty:\n",
    "                        item_info = {}\n",
    "                        for col in item_row.columns:\n",
    "                            item_info[col] = item_row.iloc[0][col]\n",
    "                        additional_items.append(item_info)\n",
    "                        if len(valid_recommendations) + len(additional_items) >= num_recommendations:\n",
    "                            break\n",
    "            \n",
    "            valid_recommendations.extend(additional_items)\n",
    "        \n",
    "        # Limit to requested number\n",
    "        valid_recommendations = valid_recommendations[:num_recommendations]\n",
    "        \n",
    "        print(f\"Generated {len(valid_recommendations)} personalized recommendations for user {user_id}\")\n",
    "        return valid_recommendations\n",
    "    \n",
    "    def visualize_personalization(self, user_id1, user_id2):\n",
    "        \"\"\"\n",
    "        Visualize how two users in the same cluster still get different recommendations.\n",
    "        This helps explain the personalization aspect of the system.\n",
    "        \"\"\"\n",
    "        # Check if both users are in the same cluster\n",
    "        cluster_id1 = self.user_to_cluster.get(user_id1)\n",
    "        cluster_id2 = self.user_to_cluster.get(user_id2)\n",
    "        \n",
    "        if cluster_id1 is None or cluster_id2 is None:\n",
    "            print(\"One or both users not found.\")\n",
    "            return\n",
    "        \n",
    "        if cluster_id1 != cluster_id2:\n",
    "            print(f\"Users {user_id1} and {user_id2} are in different clusters ({cluster_id1} and {cluster_id2}).\")\n",
    "            print(\"Please select two users from the same cluster to visualize personalization.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Users {user_id1} and {user_id2} are both in cluster {cluster_id1}.\")\n",
    "        print(\"Generating recommendations for both users to demonstrate personalization...\")\n",
    "        \n",
    "        # Generate recommendations for both users\n",
    "        recs1 = self.generate_recommendations(user_id1, num_recommendations=5)\n",
    "        recs2 = self.generate_recommendations(user_id2, num_recommendations=5)\n",
    "        \n",
    "        # Compare recommendations\n",
    "        rec_ids1 = [item['item_id'] for item in recs1]\n",
    "        rec_ids2 = [item['item_id'] for item in recs2]\n",
    "        \n",
    "        common_items = set(rec_ids1).intersection(set(rec_ids2))\n",
    "        \n",
    "        print(\"\\nDemonstrating Personalization:\")\n",
    "        print(f\"Recommendations for User {user_id1}:\")\n",
    "        for i, item in enumerate(recs1):\n",
    "            print(f\"  {i+1}. {item['name']} (ID: {item['item_id']})\")\n",
    "        \n",
    "        print(f\"\\nRecommendations for User {user_id2}:\")\n",
    "        for i, item in enumerate(recs2):\n",
    "            print(f\"  {i+1}. {item['name']} (ID: {item['item_id']})\")\n",
    "        \n",
    "        print(f\"\\nCommon recommendations: {len(common_items)} items\")\n",
    "        print(f\"Different recommendations: {5 - len(common_items)} items\")\n",
    "        print(f\"Personalization rate: {((5 - len(common_items)) / 5) * 100:.1f}%\")\n",
    "        \n",
    "        # Show personalized scores for a few items\n",
    "        print(\"\\nPersonalized scores for sample items:\")\n",
    "        sample_items = list(set(rec_ids1 + rec_ids2))[:5]\n",
    "        \n",
    "        scores1 = self.get_personalized_item_scores(user_id1)\n",
    "        scores2 = self.get_personalized_item_scores(user_id2)\n",
    "        \n",
    "        print(f\"{'Item ID':<10} | {'User '+str(user_id1):<15} | {'User '+str(user_id2):<15} | Difference\")\n",
    "        print(\"-\" * 55)\n",
    "        \n",
    "        for item_id in sample_items:\n",
    "            item_idx = list(self.idx_to_item_id.keys())[list(self.idx_to_item_id.values()).index(item_id)]\n",
    "            score1 = scores1[item_idx]\n",
    "            score2 = scores2[item_idx]\n",
    "            diff = abs(score1 - score2)\n",
    "            \n",
    "            print(f\"{item_id:<10} | {score1:<15.4f} | {score2:<15.4f} | {diff:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing EnhancedClusterHallAgent4Rec...\n",
      "Created interaction matrix of shape (5, 10)\n",
      "Loaded data: 5 users, 10 items, 13 interactions\n",
      "\n",
      "Training the model...\n",
      "Clustering 10 items into 8 clusters...\n",
      "Created user-cluster matrix of shape (5, 8)\n",
      "Item clustering complete. Cluster distribution:\n",
      "Cluster 5: 2 items\n",
      "Cluster 4: 1 items\n",
      "Cluster 0: 1 items\n",
      "Cluster 1: 1 items\n",
      "Cluster 6: 2 items\n",
      "Cluster 3: 1 items\n",
      "Cluster 2: 1 items\n",
      "Cluster 7: 1 items\n",
      "Starting hallucination-aware matrix factorization...\n",
      "Iteration 10/20, Error: 0.9974, Learning Rate: 0.009991\n",
      "Iteration 20/20, Error: 0.9633, Learning Rate: 0.009981\n",
      "Matrix factorization complete\n",
      "Clustering 5 users into 5 clusters...\n",
      "User clustering complete. Cluster distribution:\n",
      "Cluster 0: 1 users\n",
      "Cluster 1: 1 users\n",
      "Cluster 2: 1 users\n",
      "Cluster 3: 1 users\n",
      "Cluster 4: 1 users\n",
      "Computing cluster-level item ratings...\n",
      "Initializing 5 representative agents (instead of 5 user agents)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized 5 cluster representative agents\n",
      "EnhancedClusterHallAgent4Rec training complete!\n",
      "Not enough users in cluster 0\n",
      "\n",
      "\n",
      "===== CROSS-CLUSTER COMPARISON =====\n",
      "Comparing users from different clusters:\n",
      "\n",
      "Analyzing personalization for users 2 and 5\n",
      "User 2 cluster: 0\n",
      "User 5 cluster: 1\n",
      "\n",
      "Top 10 items for User 2:\n",
      "  1. 3.0 - 1.0\n",
      "  2. 1.0 - 2.0\n",
      "  3. 0.0 - 0.0\n",
      "  4. 6.0 - 1.0\n",
      "  5. 4.0 - 2.0\n",
      "  6. 2.0 - 0.0\n",
      "  7. 9.0 - 1.0\n",
      "  8. 8.0 - 0.0\n",
      "  9. 7.0 - 2.0\n",
      "  10. 5.0 - 0.0\n",
      "\n",
      "Top 10 items for User 5:\n",
      "  1. 7.0 - 2.0\n",
      "  2. 5.0 - 0.0\n",
      "  3. 2.0 - 0.0\n",
      "  4. 0.0 - 0.0\n",
      "  5. 9.0 - 1.0\n",
      "  6. 4.0 - 2.0\n",
      "  7. 6.0 - 1.0\n",
      "  8. 3.0 - 1.0\n",
      "  9. 8.0 - 0.0\n",
      "  10. 1.0 - 2.0\n",
      "\n",
      "Number of common items in top 10: 10\n",
      "Personalization rate: 0.0%\n",
      "\n",
      "Category distribution for User 2:\n",
      "  1.0: 3 items\n",
      "  2.0: 3 items\n",
      "  0.0: 4 items\n",
      "\n",
      "Category distribution for User 5:\n",
      "  2.0: 3 items\n",
      "  0.0: 4 items\n",
      "  1.0: 3 items\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import getpass\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Import the class (assuming it's in a file called enhanced_hallagent.py)\n",
    "# from enhanced_hallagent import EnhancedClusterHallAgent4Rec\n",
    "\n",
    "\n",
    "# Step 2: Train the model and generate recommendations\n",
    "def run_example():\n",
    "    # Create sample dataset\n",
    "       # Create sample data\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    # User data\n",
    "    user_data = pd.DataFrame({\n",
    "        'user_id': [1, 2, 3, 4, 5],\n",
    "        'age': [25, 30, 35, 40, 45],\n",
    "        'gender': ['M', 'F', 'M', 'F', 'M'],\n",
    "        'occupation': ['student', 'engineer', 'doctor', 'artist', 'teacher']\n",
    "    })\n",
    "    \n",
    "    # Item data\n",
    "    item_data = pd.DataFrame({\n",
    "        'item_id': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
    "        'name': ['Item A', 'Item B', 'Item C', 'Item D', 'Item E', \n",
    "                 'Item F', 'Item G', 'Item H', 'Item I', 'Item J'],\n",
    "        'category': ['books', 'electronics', 'books', 'clothing', 'electronics',\n",
    "                    'books', 'clothing', 'electronics', 'books', 'clothing'],\n",
    "        'price': [10, 50, 15, 30, 100, 20, 25, 80, 12, 35],\n",
    "        'popularity': [0.8, 0.6, 0.9, 0.7, 0.5, 0.4, 0.7, 0.6, 0.3, 0.8]\n",
    "    })\n",
    "    label_encoders = {}\n",
    "    for col in ['gender', 'occupation']:\n",
    "        le = LabelEncoder()\n",
    "        user_data[col] = le.fit_transform(user_data[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    for col in ['category','name']:\n",
    "        le = LabelEncoder()\n",
    "        item_data[col] = le.fit_transform(item_data[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    interactions = pd.DataFrame({\n",
    "        'user_id': [1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 5],\n",
    "        'item_id': [101, 103, 105, 102, 104, 103, 106, 109, 105, 107, 101, 108, 110],\n",
    "        'timestamp': [1615000000, 1615100000, 1615200000, 1615300000, 1615400000,\n",
    "                     1615500000, 1615600000, 1615700000, 1615800000, 1615900000,\n",
    "                     1616000000, 1616100000, 1616200000]\n",
    "    })\n",
    "    \n",
    "    # Test interactions\n",
    "    test_interactions = pd.DataFrame({\n",
    "        'user_id': [1, 2, 3, 4, 5],\n",
    "        'item_id': [106, 101, 102, 108, 103]\n",
    "    })\n",
    "    \n",
    "    \n",
    "    # Initialize the model\n",
    "    print(\"\\nInitializing EnhancedClusterHallAgent4Rec...\")\n",
    "    model = EnhancedClusterHallAgent4Rec(\n",
    "        num_user_clusters=5,  # Using 5 clusters for this example\n",
    "        num_clusters=8,       # Item clusters\n",
    "        latent_dim=10,        # Low dimension for faster computation\n",
    "        lambda_u=0.1,\n",
    "        lambda_v=0.1,\n",
    "        lambda_h=1.0,\n",
    "        personalization_weight=0.7,  # Balance between user and cluster preferences\n",
    "        learning_rate=0.01,\n",
    "        max_iterations=20     # Reduced for this example\n",
    "    )\n",
    "    \n",
    "    # Load data\n",
    "    model.load_data(user_data, item_data, interactions)\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"\\nTraining the model...\")\n",
    "    model.train()\n",
    "    \n",
    "    # Select two users from the same cluster for comparison\n",
    "    cluster_id = 0  # Choose first cluster\n",
    "    users_in_cluster = [user_id for user_id, cid in model.user_to_cluster.items() \n",
    "                       if cid == cluster_id]\n",
    "    \n",
    "    if len(users_in_cluster) >= 2:\n",
    "        user1 = users_in_cluster[0]\n",
    "        user2 = users_in_cluster[1]\n",
    "        \n",
    "        print(f\"\\nSelected users {user1} and {user2} from same cluster {cluster_id}\")\n",
    "        \n",
    "        # Get user details\n",
    "        user1_details = user_data[user_data['user_id'] == user1].iloc[0]\n",
    "        user2_details = user_data[user_data['user_id'] == user2].iloc[0]\n",
    "        \n",
    "        print(f\"\\nUser {user1} details:\")\n",
    "        for col, val in user1_details.items():\n",
    "            print(f\"  {col}: {val}\")\n",
    "            \n",
    "        print(f\"\\nUser {user2} details:\")\n",
    "        for col, val in user2_details.items():\n",
    "            print(f\"  {col}: {val}\")\n",
    "        \n",
    "        # Get interaction histories\n",
    "        user1_interactions = interactions[interactions['user_id'] == user1]\n",
    "        user2_interactions = interactions[interactions['user_id'] == user2]\n",
    "        \n",
    "        print(f\"\\nUser {user1} interaction count: {len(user1_interactions)}\")\n",
    "        print(f\"User {user2} interaction count: {len(user2_interactions)}\")\n",
    "        \n",
    "        # Generate recommendations for both users\n",
    "        print(f\"\\nGenerating recommendations for User {user1}...\")\n",
    "        recs1 = model.generate_recommendations(user1, num_recommendations=5)\n",
    "        \n",
    "        print(f\"\\nGenerating recommendations for User {user2}...\")\n",
    "        recs2 = model.generate_recommendations(user2, num_recommendations=5)\n",
    "        \n",
    "        # Display recommendations\n",
    "        print(f\"\\nRecommendations for User {user1}:\")\n",
    "        for i, rec in enumerate(recs1, 1):\n",
    "            print(f\"  {i}. {rec['name']} - {rec['category']} (${rec['price']})\")\n",
    "        \n",
    "        print(f\"\\nRecommendations for User {user2}:\")\n",
    "        for i, rec in enumerate(recs2, 1):\n",
    "            print(f\"  {i}. {rec['name']} - {rec['category']} (${rec['price']})\")\n",
    "        \n",
    "        # Analyze personalization\n",
    "        print(\"\\nDemonstrating personalization within the same cluster:\")\n",
    "        model.visualize_personalization(user1, user2)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Not enough users in cluster {cluster_id}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Step 3: Analyze personalized scores\n",
    "def analyze_personalization(model, user_id1, user_id2):\n",
    "    \"\"\"Analyze how personalization varies between two users\"\"\"\n",
    "    cluster_id1 = model.user_to_cluster.get(user_id1)\n",
    "    cluster_id2 = model.user_to_cluster.get(user_id2)\n",
    "    \n",
    "    print(f\"\\nAnalyzing personalization for users {user_id1} and {user_id2}\")\n",
    "    print(f\"User {user_id1} cluster: {cluster_id1}\")\n",
    "    print(f\"User {user_id2} cluster: {cluster_id2}\")\n",
    "    \n",
    "    # Get personalized scores\n",
    "    scores1 = model.get_personalized_item_scores(user_id1)\n",
    "    scores2 = model.get_personalized_item_scores(user_id2)\n",
    "    \n",
    "    # Find top items for each user\n",
    "    top_items1 = np.argsort(scores1)[::-1][:10]\n",
    "    top_items2 = np.argsort(scores2)[::-1][:10]\n",
    "    \n",
    "    # Convert to actual item IDs\n",
    "    top_item_ids1 = [model.idx_to_item_id[idx] for idx in top_items1 if idx in model.idx_to_item_id]\n",
    "    top_item_ids2 = [model.idx_to_item_id[idx] for idx in top_items2 if idx in model.idx_to_item_id]\n",
    "    \n",
    "    # Get item details\n",
    "    top_items1_details = []\n",
    "    for item_id in top_item_ids1:\n",
    "        item_row = model.item_data[model.item_data['item_id'] == item_id]\n",
    "        if not item_row.empty:\n",
    "            top_items1_details.append({\n",
    "                'item_id': item_id,\n",
    "                'name': item_row.iloc[0]['name'],\n",
    "                'category': item_row.iloc[0]['category']\n",
    "            })\n",
    "    \n",
    "    top_items2_details = []\n",
    "    for item_id in top_item_ids2:\n",
    "        item_row = model.item_data[model.item_data['item_id'] == item_id]\n",
    "        if not item_row.empty:\n",
    "            top_items2_details.append({\n",
    "                'item_id': item_id,\n",
    "                'name': item_row.iloc[0]['name'],\n",
    "                'category': item_row.iloc[0]['category']\n",
    "            })\n",
    "    \n",
    "    # Print top items\n",
    "    print(f\"\\nTop 10 items for User {user_id1}:\")\n",
    "    for i, item in enumerate(top_items1_details, 1):\n",
    "        print(f\"  {i}. {item['name']} - {item['category']}\")\n",
    "    \n",
    "    print(f\"\\nTop 10 items for User {user_id2}:\")\n",
    "    for i, item in enumerate(top_items2_details, 1):\n",
    "        print(f\"  {i}. {item['name']} - {item['category']}\")\n",
    "    \n",
    "    # Analyze overlap\n",
    "    common_items = set(top_item_ids1).intersection(set(top_item_ids2))\n",
    "    print(f\"\\nNumber of common items in top 10: {len(common_items)}\")\n",
    "    print(f\"Personalization rate: {((10 - len(common_items)) / 10) * 100:.1f}%\")\n",
    "    \n",
    "    # Analyze categorical preferences\n",
    "    cat_counts1 = {}\n",
    "    for item in top_items1_details:\n",
    "        cat = item['category']\n",
    "        cat_counts1[cat] = cat_counts1.get(cat, 0) + 1\n",
    "    \n",
    "    cat_counts2 = {}\n",
    "    for item in top_items2_details:\n",
    "        cat = item['category']\n",
    "        cat_counts2[cat] = cat_counts2.get(cat, 0) + 1\n",
    "    \n",
    "    print(f\"\\nCategory distribution for User {user_id1}:\")\n",
    "    for cat, count in cat_counts1.items():\n",
    "        print(f\"  {cat}: {count} items\")\n",
    "    \n",
    "    print(f\"\\nCategory distribution for User {user_id2}:\")\n",
    "    for cat, count in cat_counts2.items():\n",
    "        print(f\"  {cat}: {count} items\")\n",
    "\n",
    "# Run the entire example\n",
    "if __name__ == \"__main__\":\n",
    "    model = run_example()\n",
    "    \n",
    "    # Get two users from different clusters for comparison\n",
    "    user_from_cluster0 = next((uid for uid, cid in model.user_to_cluster.items() if cid == 0), None)\n",
    "    user_from_cluster1 = next((uid for uid, cid in model.user_to_cluster.items() if cid == 1), None)\n",
    "    \n",
    "    if user_from_cluster0 and user_from_cluster1:\n",
    "        print(\"\\n\\n===== CROSS-CLUSTER COMPARISON =====\")\n",
    "        print(\"Comparing users from different clusters:\")\n",
    "        analyze_personalization(model, user_from_cluster0, user_from_cluster1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
